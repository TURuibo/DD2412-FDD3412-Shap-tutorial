{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaple value tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the methods for the explanability and interpretibility of machine learning models, shapley-value based methods are one commonly used class with theoretical guarantee. In this tutorial, we will mainly focus on the package SHAP and  \n",
    "1. reimplement the simplified Kernel SHAP for understanding how it works and how to use the package for applications;\n",
    "2. apply Kernel SHAP to explaining the results of a neural network in a regression task;\n",
    "3. apply Kernel SHAP to the results of sklearn models on the iris dataset;\n",
    "4. apply Kernel SHAP to explaining the sentiment analysis results.\n",
    "\n",
    "The tutorial is mainly adapted from the official documents of [flax](https://flax.readthedocs.io/en/latest/notebooks/flax_basics.html) and [shap](https://github.com/slundberg/shap#citations). \n",
    "\n",
    "After finishing 3 and 4, one can be able to apply shap to applications. A complete of 3 and 4 can be awarded with the basic points.\n",
    "\n",
    "After finishing 1 and 2, one can be able to understand the basics of Kernel SHAP and build neural networks with flax. A complete of 1 and 2 can be awarded with bonus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install shap package\n",
    "The [shap package](https://github.com/slundberg/shap) is in general based on the work   \n",
    "* [Lundberg, Scott M., and Su-In Lee. \"A unified approach to interpreting model predictions.\" Proceedings of the 31st international conference on neural information processing systems. 2017.](https://papers.nips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART I: Kernel SHAP\n",
    "In this tutorial, we focus on Kernel SHAP which approximates shapely values. The computation mehtods has been introduced in Theorem 2 of [(Lundberg, Scott M., and Su-In Lee, 2017)](https://papers.nips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf).\n",
    "Interestingly, one can implement the method with weighted linear regression. In this part,\n",
    "* We first apply Kernel SHAP in shap to a simple linear function;\n",
    "* We then reimplement Kernel SHAP from scratch and compare the result with Kernel SHAP in shap;\n",
    "* Finally, we build a neural network for a simple (non)-linear regression task and apply Kernel SHAP to explain its results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SHAP for linear functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Input $\\mathbf{x}_i$ is a four-dimensional vector;\n",
    "* The unknown function is $f(\\mathbf{x}_i) = \\mathbf{\\beta} \\cdot \\mathbf{x}_i + 10$, where $\\beta$ and $10$ are the function parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 4\n",
    "np.random.seed(1)\n",
    "x = np.random.randn(M)\n",
    "def f(X):\n",
    "    np.random.seed(0)\n",
    "    beta = np.random.rand(X.shape[-1])\n",
    "    return np.dot(X,beta) + 10\n",
    "f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a explainer with Kernel SHAP in shap\n",
    "Please fill in this code block to create a explainer with kernel SHAP in [the shap package](https://github.com/slundberg/shap#citationshttps://github.com/slundberg/shap#citations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in this code block to print the shap values for explaining the $f(\\mathbf{x}_i)$ where the input $\\mathbf{x}_i$ and the function parameters $\\beta$ are randomly generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values = ...\n",
    "\n",
    "print(\"shap_values =\", shap_values)\n",
    "print(\"base value =\", explainer.expected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Kernel SHAP with weighted linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please reimplement Kernel SHAP from scratch. You may need to consider Theorem 2 of [(Lundberg, Scott M., and Su-In Lee, 2017)](https://papers.nips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Please finish the function ####\n",
    "def kernel_shap(...):\n",
    "    ...\n",
    "    return base_value, shap_values\n",
    "#### END ####\n",
    "\n",
    "M = 4\n",
    "np.random.seed(1)\n",
    "x = np.random.randn(M)\n",
    "\n",
    "#### Call the function ####\n",
    "phi = kernel_shap(...)\n",
    "#### END ####\n",
    "\n",
    "base_value = phi[-1]\n",
    "shap_values = phi[:-1]\n",
    "\n",
    "print(\"  reference =\", reference)\n",
    "print(\"          x =\", x)\n",
    "print(\"shap_values =\", shap_values)\n",
    "print(\" base_value =\", base_value)\n",
    "print(\"   sum(phi) =\", np.sum(phi))\n",
    "print(\"       f(x) =\", f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel SHAP for black box methods\n",
    "In this part, we will \n",
    "* first generate synthetic datasets X ( a set of four-dimensional vectors) and Y (regressopm target);\n",
    "* then, build a simple neural network with [jax](https://github.com/google/jax) and [flax](https://github.com/google/flax).\n",
    "* finally, apply KPernel SHAP to the results of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install jax\n",
    "!pip install jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install flax\n",
    "!pip install --upgrade pip jax jaxlib\n",
    "!pip install --upgrade git+https://github.com/google/flax.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "import jax\n",
    "from jax import value_and_grad,lax, random, numpy as jnp\n",
    "from typing import Any, Callable, Sequence, Optional\n",
    "from flax.core import freeze, unfreeze\n",
    "from flax import optim\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generate synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ y = W \\cdot \\sin(\\mathbf{x}) + b + 0.1 \\epsilon,$\n",
    "where $W$ and $b$ are function parameters and it is a nonlinear function because of $\\sin(\\cdot)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set problem dimensions\n",
    "nsamples = 5000\n",
    "xdim = 4\n",
    "ydim = 1\n",
    "\n",
    "# Generate random ground truth W and b\n",
    "key = random.PRNGKey(0)\n",
    "k1, k2 = random.split(key)\n",
    "W = random.normal(k1, (xdim, ydim))\n",
    "b = 10.0\n",
    "true_params = freeze({'params': {'bias': b, 'kernel': W}})\n",
    "\n",
    "# Generate samples with additional noise\n",
    "ksample, knoise = random.split(k1)\n",
    "x_samples = random.normal(ksample, (nsamples, xdim))\n",
    "\n",
    "y_samples = jnp.dot(jnp.sin(x_samples), W) + b\n",
    "y_samples += 0.1*random.normal(knoise,(nsamples, ydim)) # Adding noise\n",
    "print('x shape:', x_samples.shape, '; y shape:', y_samples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a neural network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBNN(nn.Module):\n",
    "    features: Sequence[int]\n",
    "\n",
    "    def setup(self):\n",
    "    # we automatically know what to do with lists, dicts of submodules\n",
    "        self.layers = [nn.Dense(feat) for feat in self.features]\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        \n",
    "        for i, lyr in enumerate(self.layers):\n",
    "            x = lyr(x)\n",
    "            if i != len(self.layers) - 1:\n",
    "                x = nn.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define a loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in this code block with your loss function (you may consider least square error for training on this simple scenario)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss(...):\n",
    "#     return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Initialize a neural network and train it with the dataset\n",
    "One may consider to split the dataset into training and testing datasets and then train with batches.  \n",
    "One could also consider to train with all data as linear regression, since this is a relatively simple case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature = xdim\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "key, subkey = random.split(key)\n",
    "\n",
    "x = np.random.randn(num_feature)\n",
    "model = BBNN(features=[2, 5,1])  # define a customized neural network\n",
    "params = model.init(subkey, x)\n",
    "y = model.apply(params, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could implememnt gradient descent for training as in linear regression.  \n",
    "One could also use the built-in optimizer in flax, such as [optax](#https://flax.readthedocs.io/en/latest/notebooks/flax_basics.html#Optimizing-with-Optax).  \n",
    "Please fill in the training process in the following code block: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Training #####\n",
    "\n",
    "##### END #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:  define a prediction function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_NN(X,params=params,model=model):\n",
    "    return model.apply(params, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground-true function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X,W=W,b=b):\n",
    "    W = np.array(W.reshape(-1))\n",
    "    return np.dot(np.sin(X), W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the prediction function f_NN with Kernal SHAP in shap:  \n",
    "Please fill in the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x_samples[0,:])\n",
    "\n",
    "######## create an explainer with kernel SHAP ########\n",
    "explainer = ...\n",
    "shap_values = ...\n",
    "######## END ########\n",
    "\n",
    "print(\"input =\", x)\n",
    "print(\"output =\",f_NN(x))\n",
    "print(\"ground truth =\",f(x))\n",
    "print(\"shap_values =\", shap_values)\n",
    "print(\"base value =\", explainer.expected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: compare with Kernel SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## create an explainer with kernel SHAP ########\n",
    "\n",
    "\n",
    "explainer = ...\n",
    "shap_values = ...\n",
    "######## END ########\n",
    "print(\"input =\", x)\n",
    "print(\"output =\",f(x))\n",
    "print(\"shap_values =\", shap_values)\n",
    "print(\"base value =\", explainer.expected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART II: Application of Kernel SHAP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load iris dataset with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(*shap.datasets.iris(), test_size=0.2, random_state=0)\n",
    "\n",
    "# rather than use the whole training set to estimate expected values, we could summarize with\n",
    "# a set of weighted kmeans, each weighted by the number of points they represent. But this dataset\n",
    "# is so small we don't worry about it\n",
    "#X_train_summary = shap.kmeans(X_train, 50)\n",
    "\n",
    "def print_accuracy(f):\n",
    "    print(\"Accuracy = {0}%\".format(100*np.sum(f(X_test) == Y_test)/len(Y_test)))\n",
    "    time.sleep(0.5) # to let the print get out before any progress bars\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please use the model \"KNeighborsClassifier\" in sklearn and fit the model with the training dataset,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### define a model ######\n",
    "model = ...\n",
    "###### END ######\n",
    "\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please create a explainer for the model with Kernel SHAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = ...\n",
    "shap_values = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please draw the force plot of the shap values for the first sample \"X_test.iloc[0,:]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please draw all the test data with force plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = ...\n",
    "shap.force_plot(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please try \"summery_plot\" in shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use shap.explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can not only use kernel shap but also other explainers. In this part we try shap.explainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: model.predict_proba(x)[:,1]\n",
    "med = X_train.median().values.reshape((1,X_train.shape[1]))\n",
    "\n",
    "explainer = shap.Explainer(f, med)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:,\"petal length (cm)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis\n",
    "Classify the \"positive\" and \"negative\" sentiment of IMDB reviews.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the dataset of IMDB reviews** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus,y = shap.datasets.imdb()\n",
    "corpus_train, corpus_test, y_train, y_test = train_test_split(corpus, y, test_size=0.2, random_state=7)\n",
    "corpus_train, corpus_test, y_train, y_test = corpus_train[:10000],corpus_test[:500],y_train[:10000],y_test[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess and Create training and testing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10)\n",
    "X_train = vectorizer.fit_transform(corpus_train).toarray() \n",
    "X_test = vectorizer.transform(corpus_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a logistic classification model.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.LogisticRegression(penalty=\"l2\", C=0.1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build explainer**  \n",
    "Please fill in your answer in the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Please fill in your answer here ######\n",
    "explainer = shap.Explainer(...)\n",
    "shap_values = ...\n",
    "###### END ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please plot 10 features with beeswarm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 10\n",
    "print(\"Positive\" if y_test[ind] else \"Negative\", \"Review:\")\n",
    "print(corpus_test[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please plot the force plot for the review, corpus_test[10]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.force(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please also try the bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
